{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4229472,"sourceType":"datasetVersion","datasetId":2492800}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport math\nimport json\nimport time\nimport random\nimport argparse\nimport warnings\nfrom dataclasses import dataclass\nfrom typing import List, Tuple, Dict, Optional, Union\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ntry:\n    import timm\nexcept ImportError:\n    timm = None\n\ntry:\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n    from sklearn.calibration import calibration_curve\nexcept Exception:\n    train_test_split = None\n    accuracy_score = None\n    f1_score = None\n    confusion_matrix = None\n    classification_report = None\n    calibration_curve = None\n\n# Grad-CAM (installed on Kaggle with: pip install pytorch-grad-cam)\ntry:\n    from pytorch_grad_cam import GradCAM\n    from pytorch_grad_cam.utils.image import show_cam_on_image\n    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nexcept Exception:\n    GradCAM = None\n    show_cam_on_image = None\n    ClassifierOutputTarget = None\n\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\n# Alzheimer MRI Dataset - Focus on cognitive decline progression\nALZHEIMER_LABEL_MAP = {\n    'nondemented': 0,           # Cognitively normal\n    'verymilddemented': 1,      # Very mild cognitive decline (CDR 0.5)\n    'milddemented': 2,          # Mild dementia (CDR 1)\n    'moderatedemented': 3,      # Moderate dementia (CDR 2)\n}\n\n# Clinical significance for research narrative\nALZHEIMER_CLINICAL_INFO = {\n    0: {'name': 'Cognitively Normal', 'cdr': 0, 'description': 'No cognitive impairment detected'},\n    1: {'name': 'Very Mild Dementia', 'cdr': 0.5, 'description': 'Questionable dementia, very mild cognitive decline'},\n    2: {'name': 'Mild Dementia', 'cdr': 1, 'description': 'Mild dementia with clear functional impairment'},\n    3: {'name': 'Moderate Dementia', 'cdr': 2, 'description': 'Moderate dementia requiring substantial care'}\n}\n\n\n# ------------------------------\n# Utilities & Setup\n# ------------------------------\n\ndef set_seed(seed: int) -> None:\n    \"\"\"Set reproducible seed for all random number generators\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    # Additional deterministic settings for reproducibility\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\ndef worker_init_fn(worker_id: int) -> None:\n    \"\"\"Worker initialization for DataLoader reproducibility\"\"\"\n    np.random.seed(SEED + worker_id)\n\n\ndef exists(path: str) -> bool:\n    return path is not None and os.path.exists(path)\n\n\ndef ensure_dir(path: str) -> None:\n    if not exists(path):\n        os.makedirs(path, exist_ok=True)\n\n\ndef device() -> torch.device:\n    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# ------------------------------\n# Enhanced Dataset Implementation\n# ------------------------------\n\n@dataclass\nclass ImageRecord:\n    image_path: str\n    label: int\n    metadata: Optional[Dict] = None\n\n\nclass AlzheimerDataset(Dataset):\n    \"\"\"\n    Enhanced Alzheimer MRI Dataset with sophisticated augmentation\n    and proper normalization for medical imaging.\n    \"\"\"\n    def __init__(\n        self,\n        records: List[ImageRecord],\n        image_size: int = 224,\n        augment: bool = False,\n        mean: Tuple[float, float, float] = (0.485, 0.456, 0.406),\n        std: Tuple[float, float, float] = (0.229, 0.224, 0.225),\n    ) -> None:\n        self.records = records\n        self.image_size = image_size\n        self.augment = augment\n        self.mean = mean\n        self.std = std\n\n    def __len__(self) -> int:\n        return len(self.records)\n\n    def _apply_medical_augmentation(self, img: Image.Image) -> Image.Image:\n        \"\"\"Apply medically-appropriate augmentations that preserve diagnostic features\"\"\"\n        # Horizontal flip (brain is roughly symmetric)\n        if random.random() < 0.5:\n            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n        \n        # Small rotation (Â±5 degrees) to account for patient positioning\n        if random.random() < 0.3:\n            angle = random.uniform(-5, 5)\n            img = img.rotate(angle, fillcolor=0)\n        \n        # Slight brightness/contrast adjustment (medical imaging variations)\n        if random.random() < 0.3:\n            from PIL import ImageEnhance\n            enhancer = ImageEnhance.Brightness(img)\n            img = enhancer.enhance(random.uniform(0.9, 1.1))\n            \n            enhancer = ImageEnhance.Contrast(img)\n            img = enhancer.enhance(random.uniform(0.9, 1.1))\n        \n        return img\n\n    def __getitem__(self, idx: int):\n        rec = self.records[idx]\n        \n        try:\n            img = Image.open(rec.image_path).convert('RGB')\n        except Exception as e:\n            # Fallback for corrupted images\n            print(f\"Warning: Could not load image {rec.image_path}: {e}\")\n            img = Image.new('RGB', (self.image_size, self.image_size), color=(128, 128, 128))\n        \n        # Resize with high-quality resampling for medical images\n        img = img.resize((self.image_size, self.image_size), Image.LANCZOS)\n\n        if self.augment:\n            img = self._apply_medical_augmentation(img)\n\n        # Normalize for ImageNet pretrained models\n        img_np = np.array(img).astype(np.float32) / 255.0\n        img_np = (img_np - np.array(self.mean, dtype=np.float32)) / np.array(self.std, dtype=np.float32)\n        img_np = np.transpose(img_np, (2, 0, 1))\n\n        x = torch.from_numpy(img_np).float()  # Ensure float32\n        y = torch.tensor(rec.label, dtype=torch.long)\n        \n        return x, y\n\n\ndef load_alzheimer_records(dataset_root: str) -> List[ImageRecord]:\n    \"\"\"\n    Load Alzheimer MRI dataset with robust error handling and validation.\n    Supports multiple folder structures and naming conventions.\n    \"\"\"\n    label_map = ALZHEIMER_LABEL_MAP\n    \n    def _find_class_dirs(root: str, class_names_lower: List[str]) -> Dict[str, List[str]]:\n        \"\"\"Find directories containing each class\"\"\"\n        mapping: Dict[str, List[str]] = {cn: [] for cn in class_names_lower}\n        \n        for dirpath, dirnames, filenames in os.walk(root):\n            base = os.path.basename(dirpath).lower()\n            # Handle various naming conventions\n            normalized_base = base.replace('_', '').replace('-', '').replace(' ', '')\n            \n            for class_name in class_names_lower:\n                normalized_class = class_name.replace('_', '').replace('-', '').replace(' ', '')\n                if normalized_base == normalized_class or base == class_name:\n                    mapping[class_name].append(dirpath)\n                    break\n        \n        return mapping\n\n    def _collect_images_from_dirs(dirs: List[str]) -> List[str]:\n        \"\"\"Collect all valid image files from directories\"\"\"\n        images: List[str] = []\n        valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}\n        \n        for d in dirs:\n            if not exists(d):\n                continue\n            for fname in os.listdir(d):\n                fpath = os.path.join(d, fname)\n                if (os.path.isfile(fpath) and \n                    any(fname.lower().endswith(ext) for ext in valid_extensions)):\n                    images.append(fpath)\n        return images\n\n    class_names_lower = list(label_map.keys())\n    dir_map = _find_class_dirs(dataset_root, class_names_lower)\n    \n    records: List[ImageRecord] = []\n    class_counts = {}\n    \n    for class_name_lower, label_idx in label_map.items():\n        dirs = dir_map.get(class_name_lower, [])\n        if not dirs:\n            print(f\"Warning: No directories found for class '{class_name_lower}'\")\n            continue\n            \n        imgs = _collect_images_from_dirs(dirs)\n        class_counts[class_name_lower] = len(imgs)\n        \n        for img_path in imgs:\n            records.append(ImageRecord(\n                image_path=img_path, \n                label=label_idx,\n                metadata={'class_name': class_name_lower}\n            ))\n    \n    if len(records) == 0:\n        raise RuntimeError(\n            f\"No images found under {dataset_root}. \"\n            f\"Expected class folders: {list(label_map.keys())}\"\n        )\n    \n    print(\"Dataset loaded successfully:\")\n    for class_name, count in class_counts.items():\n        clinical_info = ALZHEIMER_CLINICAL_INFO[label_map[class_name]]\n        print(f\"  {class_name}: {count} images (CDR {clinical_info['cdr']} - {clinical_info['name']})\")\n    \n    return records\n\n\n# ------------------------------\n# Advanced Model Architecture\n# ------------------------------\n\nclass MedicalDropout(nn.Module):\n    \"\"\"\n    Enhanced dropout specifically designed for medical imaging.\n    Implements structured dropout patterns.\n    \"\"\"\n    def __init__(self, p: float = 0.2, medical_structured: bool = True):\n        super().__init__()\n        self.p = p\n        self.medical_structured = medical_structured\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if not self.training:\n            return x\n            \n        if self.medical_structured and len(x.shape) == 4:  # For CNN features\n            # Apply spatial dropout to maintain spatial structure\n            return F.dropout2d(x, p=self.p, training=True)\n        else:\n            return F.dropout(x, p=self.p, training=True)\n\n\ndef build_simple_model(\n    model_name: str = 'resnet18', \n    num_classes: int = 4, \n    dropout: float = 0.2, \n    pretrained: bool = True\n) -> nn.Module:\n    \"\"\"\n    Build simple, reliable model for Kaggle compatibility\n    \"\"\"\n    if timm is None:\n        raise ImportError(\"timm is not installed. Please install with: pip install timm\")\n\n    model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes)\n    \n    # Simple replacement of the classifier head with standard components\n    if hasattr(model, 'fc') and isinstance(model.fc, nn.Linear):\n        in_features = model.fc.in_features\n        model.fc = nn.Sequential(\n            nn.Dropout(p=dropout),\n            nn.Linear(in_features, num_classes)\n        )\n    elif hasattr(model, 'classifier') and isinstance(model.classifier, nn.Linear):\n        in_features = model.classifier.in_features\n        model.classifier = nn.Sequential(\n            nn.Dropout(p=dropout),\n            nn.Linear(in_features, num_classes)\n        )\n    elif hasattr(model, 'head') and isinstance(model.head, nn.Linear):\n        in_features = model.head.in_features\n        model.head = nn.Sequential(\n            nn.Dropout(p=dropout),\n            nn.Linear(in_features, num_classes)\n        )\n    \n    return model\n\n\ndef build_medical_model(\n    model_name: str = 'tf_efficientnet_b0_ns', \n    num_classes: int = 4, \n    dropout: float = 0.25, \n    pretrained: bool = True\n) -> nn.Module:\n    \"\"\"\n    Build sophisticated model architecture optimized for medical imaging.\n    \"\"\"\n    if timm is None:\n        raise ImportError(\"timm is not installed. Please install with: pip install timm\")\n\n    model = timm.create_model(model_name, pretrained=pretrained)\n    \n    # Get the feature dimension\n    if hasattr(model, 'classifier') and isinstance(model.classifier, nn.Linear):\n        in_features = model.classifier.in_features\n        # Replace with medical-optimized head (using LayerNorm instead of BatchNorm)\n        model.classifier = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.LayerNorm(in_features),  # LayerNorm handles small batches better\n            MedicalDropout(p=dropout),\n            nn.Linear(in_features, in_features // 2),\n            nn.ReLU(inplace=True),\n            nn.LayerNorm(in_features // 2),  # LayerNorm instead of BatchNorm\n            MedicalDropout(p=dropout / 2),\n            nn.Linear(in_features // 2, num_classes)\n        )\n    elif hasattr(model, 'head'):\n        in_features = model.head.in_features\n        model.head = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.LayerNorm(in_features),  # LayerNorm handles small batches better\n            MedicalDropout(p=dropout),\n            nn.Linear(in_features, in_features // 2),\n            nn.ReLU(inplace=True),\n            nn.LayerNorm(in_features // 2),  # LayerNorm instead of BatchNorm\n            MedicalDropout(p=dropout / 2),\n            nn.Linear(in_features // 2, num_classes)\n        )\n    else:\n        raise ValueError(f\"Unsupported model architecture: {model_name}\")\n    \n    return model\n\n\ndef enable_mc_dropout(model: nn.Module) -> None:\n    \"\"\"Enable Monte Carlo dropout during inference\"\"\"\n    for module in model.modules():\n        if isinstance(module, (nn.Dropout, nn.Dropout2d, MedicalDropout)):\n            module.train()\n\n\n# ------------------------------\n# Advanced Uncertainty Quantification\n# ------------------------------\n\nclass AdvancedTemperatureScaling(nn.Module):\n    \"\"\"\n    Enhanced temperature scaling with class-specific temperatures\n    for better calibration in multi-class medical scenarios.\n    \"\"\"\n    def __init__(self, num_classes: int, class_specific: bool = True):\n        super().__init__()\n        self.num_classes = num_classes\n        self.class_specific = class_specific\n        \n        if class_specific:\n            self.temperatures = nn.Parameter(torch.ones(num_classes))\n        else:\n            self.temperature = nn.Parameter(torch.ones(1))\n    \n    def forward(self, logits: torch.Tensor) -> torch.Tensor:\n        if self.class_specific:\n            # Apply class-specific temperatures\n            temps = self.temperatures.unsqueeze(0).expand(logits.size(0), -1)\n            return logits / temps\n        else:\n            return logits / self.temperature\n\n\ndef fit_advanced_temperature(\n    model: nn.Module, \n    loader: DataLoader, \n    device_: torch.device, \n    num_classes: int,\n    max_iter: int = 100,\n    lr: float = 0.01\n) -> AdvancedTemperatureScaling:\n    \"\"\"Fit advanced temperature scaling for better calibration\"\"\"\n    model.eval()\n    temp_scaler = AdvancedTemperatureScaling(num_classes, class_specific=True).to(device_)\n    \n    # Collect all predictions and labels\n    all_logits = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, targets in loader:\n            images = images.to(device_)\n            targets = targets.to(device_)\n            logits = model(images)\n            all_logits.append(logits)\n            all_labels.append(targets)\n    \n    logits_tensor = torch.cat(all_logits, dim=0)\n    labels_tensor = torch.cat(all_labels, dim=0)\n    \n    # Optimize temperature parameters\n    optimizer = torch.optim.LBFGS(temp_scaler.parameters(), lr=lr, max_iter=50)\n    \n    def closure():\n        optimizer.zero_grad()\n        scaled_logits = temp_scaler(logits_tensor)\n        loss = F.cross_entropy(scaled_logits, labels_tensor)\n        loss.backward()\n        return loss\n    \n    optimizer.step(closure)\n    return temp_scaler\n\n\n# ------------------------------\n# RAPS Conformal Prediction (Enhanced)\n# ------------------------------\n\ndef compute_raps_scores_enhanced(\n    probs: np.ndarray, \n    labels: np.ndarray, \n    lambda_reg: float, \n    k_reg: int,\n    class_weights: Optional[np.ndarray] = None\n) -> np.ndarray:\n    \"\"\"\n    Enhanced RAPS with class balancing for medical datasets\n    \"\"\"\n    n, num_classes = probs.shape\n    scores = np.zeros(n, dtype=np.float32)\n    \n    if class_weights is None:\n        class_weights = np.ones(num_classes)\n    \n    for i in range(n):\n        p = probs[i]\n        y = labels[i]\n        \n        # Apply class weights to probabilities\n        p_weighted = p * class_weights\n        p_weighted = p_weighted / p_weighted.sum()  # Renormalize\n        \n        order = np.argsort(p_weighted)[::-1]\n        p_sorted = p_weighted[order]\n        \n        # Find rank of true class\n        ranks = np.empty_like(order)\n        ranks[order] = np.arange(num_classes)\n        true_rank = ranks[y]\n        \n        # Compute cumulative probability up to true class\n        cum = np.cumsum(p_sorted)\n        \n        # Add regularization penalty\n        reg = lambda_reg * max(true_rank - k_reg, 0)\n        scores[i] = cum[true_rank] + reg\n    \n    return scores\n\n\ndef adaptive_raps_quantile(scores: np.ndarray, alpha: float, n_bootstrap: int = 1000) -> Tuple[float, float]:\n    \"\"\"\n    Adaptive RAPS quantile with bootstrap confidence intervals\n    \"\"\"\n    n = len(scores)\n    k = math.ceil((n + 1) * (1 - alpha))\n    k = min(max(k, 1), n)\n    \n    # Primary quantile\n    qhat = np.partition(scores, k - 1)[k - 1]\n    \n    # Bootstrap confidence interval for quantile\n    bootstrap_qhats = []\n    for _ in range(n_bootstrap):\n        boot_indices = np.random.choice(n, size=n, replace=True)\n        boot_scores = scores[boot_indices]\n        boot_qhat = np.partition(boot_scores, k - 1)[k - 1]\n        bootstrap_qhats.append(boot_qhat)\n    \n    ci_lower = np.percentile(bootstrap_qhats, 2.5)\n    ci_upper = np.percentile(bootstrap_qhats, 97.5)\n    \n    return float(qhat), (float(ci_lower), float(ci_upper))\n\n\n# ------------------------------\n# Batch Ensemble (Optimized)\n# ------------------------------\n\nclass OptimizedBatchEnsemble(nn.Module):\n    \"\"\"\n    Optimized Batch Ensemble implementation with rank-1 perturbations\n    \"\"\"\n    def __init__(self, backbone: nn.Module, num_classes: int, ensemble_size: int = 4):\n        super().__init__()\n        self.backbone = backbone\n        self.ensemble_size = ensemble_size\n        self.num_classes = num_classes\n        \n        # Get feature dimension from backbone by examining the model structure\n        # This avoids the tensor type issues in __init__\n        if hasattr(backbone, 'num_features'):\n            self.feature_dim = backbone.num_features\n        elif hasattr(backbone, 'classifier') and hasattr(backbone.classifier, 'in_features'):\n            self.feature_dim = backbone.classifier.in_features\n        elif hasattr(backbone, 'head') and hasattr(backbone.head, 'in_features'):\n            self.feature_dim = backbone.head.in_features\n        else:\n            # Fallback: use a small dummy forward pass with proper device/dtype\n            backbone.eval()\n            device = next(backbone.parameters()).device\n            dtype = next(backbone.parameters()).dtype\n            with torch.no_grad():\n                dummy_input = torch.randn(1, 3, 224, 224, device=device, dtype=dtype)\n                try:\n                    features = backbone(dummy_input)\n                    if len(features.shape) > 2:\n                        features = F.adaptive_avg_pool2d(features, 1).flatten(1)\n                    self.feature_dim = features.shape[1]\n                except Exception as e:\n                    print(f\"Warning: Could not determine feature dimension, using default 1280: {e}\")\n                    self.feature_dim = 1280  # Default for EfficientNet-B0\n        \n        # Ensemble parameters\n        self.r_vectors = nn.Parameter(torch.randn(ensemble_size, self.feature_dim))\n        self.s_vectors = nn.Parameter(torch.randn(ensemble_size, num_classes))\n        self.shared_weight = nn.Parameter(torch.randn(num_classes, self.feature_dim))\n        self.ensemble_bias = nn.Parameter(torch.randn(ensemble_size, num_classes))\n        \n        self._init_parameters()\n    \n    def _init_parameters(self):\n        \"\"\"Initialize parameters with appropriate scaling\"\"\"\n        nn.init.normal_(self.r_vectors, std=1.0)\n        nn.init.normal_(self.s_vectors, std=1.0)\n        nn.init.kaiming_uniform_(self.shared_weight, a=math.sqrt(5))\n        nn.init.zeros_(self.ensemble_bias)\n    \n    def get_ensemble_predictions(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Get predictions from all ensemble members separately.\n        Returns: (ensemble_size, batch_size, num_classes)\n        \"\"\"\n        features = self.backbone(x)\n        if len(features.shape) > 2:\n            features = F.adaptive_avg_pool2d(features, 1).flatten(1)\n        \n        all_logits = []\n        for i in range(self.ensemble_size):\n            r = self.r_vectors[i]\n            s = self.s_vectors[i]\n            bias = self.ensemble_bias[i]\n            \n            features_perturbed = features * r.unsqueeze(0)\n            logits = F.linear(features_perturbed, self.shared_weight) + bias.unsqueeze(0)\n            logits = logits * s.unsqueeze(0)\n            all_logits.append(logits)\n        \n        return torch.stack(all_logits, dim=0)  # (ensemble_size, batch_size, num_classes)\n\n    def forward(self, x: torch.Tensor, ensemble_member: Optional[int] = None) -> torch.Tensor:\n        # Extract features from backbone\n        features = self.backbone(x)\n        if len(features.shape) > 2:\n            features = F.adaptive_avg_pool2d(features, 1).flatten(1)\n        \n        if ensemble_member is not None:\n            # Single ensemble member forward pass\n            r = self.r_vectors[ensemble_member]\n            s = self.s_vectors[ensemble_member]\n            bias = self.ensemble_bias[ensemble_member]\n            \n            # Apply rank-1 perturbation\n            features_perturbed = features * r.unsqueeze(0)\n            logits = F.linear(features_perturbed, self.shared_weight) + bias.unsqueeze(0)\n            logits = logits * s.unsqueeze(0)\n            \n            return logits\n        else:\n            # All ensemble members - return averaged logits for training\n            batch_size = features.shape[0]\n            all_logits = []\n            \n            for i in range(self.ensemble_size):\n                r = self.r_vectors[i]\n                s = self.s_vectors[i]\n                bias = self.ensemble_bias[i]\n                \n                features_perturbed = features * r.unsqueeze(0)\n                logits = F.linear(features_perturbed, self.shared_weight) + bias.unsqueeze(0)\n                logits = logits * s.unsqueeze(0)\n                all_logits.append(logits)\n            \n            # Stack and average for training compatibility\n            ensemble_logits = torch.stack(all_logits, dim=0)  # (ensemble_size, batch_size, num_classes)\n            averaged_logits = torch.mean(ensemble_logits, dim=0)  # (batch_size, num_classes)\n            \n            return averaged_logits\n\n\n# ------------------------------\n# Training & Evaluation\n# ------------------------------\n\ndef train_epoch_with_mixup(\n    model: nn.Module,\n    loader: DataLoader,\n    optimizer: torch.optim.Optimizer,\n    device_: torch.device,\n    mixup_alpha: float = 0.2\n) -> Tuple[float, float]:\n    \"\"\"Training with mixup augmentation for better generalization\"\"\"\n    model.train()\n    total_loss = 0.0\n    total_correct = 0\n    total = 0\n    \n    for images, targets in loader:\n        images = images.to(device_)\n        targets = targets.to(device_)\n        \n        # Apply mixup\n        if mixup_alpha > 0 and random.random() < 0.5:\n            lam = np.random.beta(mixup_alpha, mixup_alpha)\n            batch_size = images.size(0)\n            index = torch.randperm(batch_size).to(device_)\n            \n            mixed_images = lam * images + (1 - lam) * images[index]\n            targets_a, targets_b = targets, targets[index]\n            \n            optimizer.zero_grad(set_to_none=True)\n            logits = model(mixed_images)\n            \n            loss = lam * F.cross_entropy(logits, targets_a) + (1 - lam) * F.cross_entropy(logits, targets_b)\n        else:\n            optimizer.zero_grad(set_to_none=True)\n            logits = model(images)\n            loss = F.cross_entropy(logits, targets)\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item() * images.size(0)\n        if mixup_alpha == 0 or random.random() >= 0.5:  # Only count accuracy for non-mixup batches\n            preds = torch.argmax(logits, dim=1)\n            total_correct += (preds == targets).sum().item()\n            total += images.size(0)\n    \n    return total_loss / len(loader.dataset), total_correct / max(total, 1)\n\n\ndef comprehensive_evaluation(\n    model: nn.Module,\n    loader: DataLoader,\n    device_: torch.device,\n    class_names: List[str]\n) -> Dict:\n    \"\"\"Comprehensive evaluation with medical metrics\"\"\"\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_logits = []\n    total_loss = 0.0\n    \n    with torch.no_grad():\n        for images, targets in loader:\n            images = images.to(device_)\n            targets = targets.to(device_)\n            \n            logits = model(images)\n            loss = F.cross_entropy(logits, targets)\n            \n            total_loss += loss.item() * images.size(0)\n            \n            preds = torch.argmax(logits, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(targets.cpu().numpy())\n            all_logits.append(logits.cpu().numpy())\n    \n    all_logits = np.concatenate(all_logits, axis=0)\n    \n    # Calculate comprehensive metrics\n    accuracy = accuracy_score(all_labels, all_preds) if accuracy_score else 0.0\n    f1_macro = f1_score(all_labels, all_preds, average='macro') if f1_score else 0.0\n    f1_weighted = f1_score(all_labels, all_preds, average='weighted') if f1_score else 0.0\n    \n    results = {\n        'loss': total_loss / len(loader.dataset),\n        'accuracy': accuracy,\n        'f1_macro': f1_macro,\n        'f1_weighted': f1_weighted,\n        'logits': all_logits,\n        'predictions': all_preds,\n        'labels': all_labels\n    }\n    \n    if classification_report:\n        results['classification_report'] = classification_report(\n            all_labels, all_preds, target_names=class_names, output_dict=True\n        )\n    \n    return results\n\n\n# ------------------------------\n# Advanced Uncertainty & Ensemble Methods\n# ------------------------------\n\ndef batch_ensemble_predictions(\n    model: Union[OptimizedBatchEnsemble, nn.Module],\n    loader: DataLoader,\n    device_: torch.device,\n) -> Tuple[np.ndarray, np.ndarray, Dict[str, np.ndarray]]:\n    \"\"\"\n    Get uncertainty predictions from Batch Ensemble model\n    \"\"\"\n    model.eval()\n    all_ensemble_logits = []\n    \n    with torch.no_grad():\n        for images, _ in loader:\n            images = images.to(device_)\n            # Get all ensemble predictions: (ensemble_size, batch_size, num_classes)\n            if isinstance(model, OptimizedBatchEnsemble):\n                ensemble_logits = model.get_ensemble_predictions(images)\n            else:\n                # Fallback to MC dropout for non-batch-ensemble models\n                return monte_carlo_predictions(model, loader, device_, num_samples=15)\n            all_ensemble_logits.append(ensemble_logits.cpu().numpy())\n    \n    # Concatenate across batches: (ensemble_size, total_samples, num_classes)\n    ensemble_logits = np.concatenate(all_ensemble_logits, axis=1)\n    \n    # Convert to probabilities\n    ensemble_probs = softmax_np(ensemble_logits, axis=2)\n    \n    # Mean predictions\n    mean_predictions = np.mean(ensemble_probs, axis=0)\n    \n    # Compute uncertainty metrics\n    uncertainty_metrics = compute_uncertainty_metrics(ensemble_probs)\n    \n    return mean_predictions, ensemble_probs, uncertainty_metrics\n\n\ndef monte_carlo_predictions(\n    model: nn.Module,\n    loader: DataLoader,\n    device_: torch.device,\n    num_samples: int = 20\n) -> Tuple[np.ndarray, np.ndarray, Dict[str, np.ndarray]]:\n    \"\"\"\n    Advanced Monte Carlo dropout with comprehensive uncertainty metrics\n    \"\"\"\n    model.eval()\n    enable_mc_dropout(model)\n    \n    all_predictions = []\n    \n    # Collect MC samples\n    for _ in range(num_samples):\n        batch_logits = []\n        with torch.no_grad():\n            for images, _ in loader:\n                images = images.to(device_)\n                logits = model(images)\n                batch_logits.append(logits.cpu().numpy())\n        \n        logits = np.concatenate(batch_logits, axis=0)\n        probs = softmax_np(logits)\n        all_predictions.append(probs)\n    \n    # Stack predictions: (num_samples, num_data, num_classes)\n    mc_predictions = np.stack(all_predictions, axis=0)\n    mean_predictions = np.mean(mc_predictions, axis=0)\n    \n    # Compute comprehensive uncertainty metrics\n    uncertainty_metrics = compute_uncertainty_metrics(mc_predictions)\n    \n    return mean_predictions, mc_predictions, uncertainty_metrics\n\n\ndef compute_uncertainty_metrics(predictions: np.ndarray, eps: float = 1e-12) -> Dict[str, np.ndarray]:\n    \"\"\"\n    Compute comprehensive uncertainty metrics for ensemble predictions\n    \"\"\"\n    # predictions shape: (num_samples, num_data, num_classes)\n    mean_probs = np.mean(predictions, axis=0)\n    \n    # Total uncertainty (predictive entropy)\n    predictive_entropy = -np.sum(mean_probs * np.log(mean_probs + eps), axis=1)\n    \n    # Aleatoric uncertainty (expected entropy)\n    individual_entropies = -np.sum(predictions * np.log(predictions + eps), axis=2)\n    aleatoric_uncertainty = np.mean(individual_entropies, axis=0)\n    \n    # Epistemic uncertainty (mutual information)\n    epistemic_uncertainty = predictive_entropy - aleatoric_uncertainty\n    \n    # Confidence-based metrics\n    max_probabilities = np.max(mean_probs, axis=1)\n    confidence = max_probabilities\n    \n    # Prediction variance (another epistemic measure)\n    prediction_variance = np.var(predictions, axis=0)\n    total_variance = np.sum(prediction_variance, axis=1)\n    \n    # BALD (Bayesian Active Learning by Disagreement)\n    bald_score = epistemic_uncertainty\n    \n    return {\n        'predictive_entropy': predictive_entropy,\n        'aleatoric_uncertainty': aleatoric_uncertainty,\n        'epistemic_uncertainty': epistemic_uncertainty,\n        'confidence': confidence,\n        'prediction_variance': total_variance,\n        'bald_score': bald_score\n    }\n\n\ndef softmax_np(x: np.ndarray, axis: int = -1) -> np.ndarray:\n    \"\"\"Numerical stable softmax\"\"\"\n    x_max = np.max(x, axis=axis, keepdims=True)\n    exp_x = np.exp(x - x_max)\n    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n\n\n# ------------------------------\n# Advanced Grad-CAM with Uncertainty\n# ------------------------------\n\ndef generate_uncertainty_aware_gradcam(\n    model: nn.Module,\n    images: torch.Tensor,\n    target_class: int,\n    num_mc_samples: int = 10\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Generate Grad-CAM with uncertainty estimation using MC dropout\n    \"\"\"\n    if GradCAM is None:\n        raise ImportError(\"pytorch-grad-cam not available\")\n    \n    # Find the last convolutional layer\n    target_layers = []\n    for name, module in model.named_modules():\n        if isinstance(module, nn.Conv2d):\n            target_layers = [module]\n    \n    if not target_layers:\n        raise ValueError(\"No convolutional layers found for Grad-CAM\")\n    \n    # Standard Grad-CAM\n    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=torch.cuda.is_available())\n    model.eval()\n    \n    # Collect multiple Grad-CAM samples with MC dropout\n    enable_mc_dropout(model)\n    cam_samples = []\n    \n    for _ in range(num_mc_samples):\n        try:\n            grayscale_cam = cam(\n                input_tensor=images,\n                targets=[ClassifierOutputTarget(target_class)]\n            )\n            cam_samples.append(grayscale_cam[0])\n        except:\n            continue\n    \n    if not cam_samples:\n        # Fallback to deterministic Grad-CAM\n        model.eval()\n        grayscale_cam = cam(\n            input_tensor=images,\n            targets=[ClassifierOutputTarget(target_class)]\n        )\n        return grayscale_cam[0], np.zeros_like(grayscale_cam[0])\n    \n    # Compute mean and uncertainty\n    cam_array = np.stack(cam_samples, axis=0)\n    mean_cam = np.mean(cam_array, axis=0)\n    std_cam = np.std(cam_array, axis=0)\n    \n    return mean_cam, std_cam\n\n\n# ------------------------------\n# Main Training Pipeline\n# ------------------------------\n\ndef run_alzheimer_pipeline(\n    data_root: str,\n    output_dir: str,\n    model_name: str = 'tf_efficientnet_b0_ns',\n    image_size: int = 224,\n    batch_size: int = 16,\n    epochs: int = 15,\n    lr: float = 2e-4,\n    weight_decay: float = 1e-4,\n    alpha: float = 0.1,\n    lambda_reg: float = 0.05,\n    k_reg: int = 1,\n    dropout: float = 0.25,\n    num_workers: int = 2,\n    calib_fraction: float = 0.2,\n    val_fraction: float = 0.2,\n    mc_samples: int = 20,\n    seed: int = 42,\n    ensemble_method: str = 'batch_ensemble',\n    ensemble_size: int = 4,\n    use_mixup: bool = True,\n) -> None:\n    \"\"\"\n    Complete Alzheimer MRI analysis pipeline with state-of-the-art uncertainty quantification\n    \"\"\"\n    set_seed(seed)\n    ensure_dir(output_dir)\n    \n    print(\"=\" * 80)\n    print(\"ALZHEIMER MRI UNCERTAINTY QUANTIFICATION & EXPLAINABILITY PIPELINE\")\n    print(\"=\" * 80)\n    print(f\"ðŸ§  Focus: Alzheimer's Disease Progression Analysis\")\n    print(f\"ðŸ“Š Ensemble Method: {ensemble_method}\")\n    print(f\"ðŸŽ¯ Target: CDR-based cognitive decline classification\")\n    print(f\"âš™ï¸  Device: {device()}\")\n    print(\"=\" * 80)\n\n    # Load dataset\n    print(\"\\nðŸ“ Loading Alzheimer MRI dataset...\")\n    records = load_alzheimer_records(data_root)\n    \n    # Check class distribution\n    label_counts = {}\n    for record in records:\n        label_counts[record.label] = label_counts.get(record.label, 0) + 1\n    \n    print(f\"\\nðŸ“Š Dataset Statistics:\")\n    for label, count in sorted(label_counts.items()):\n        clinical_info = ALZHEIMER_CLINICAL_INFO[label]\n        print(f\"   {clinical_info['name']} (CDR {clinical_info['cdr']}): {count} images\")\n    \n    # Split data strategically\n    labels_all = np.array([rec.label for rec in records])\n    \n    # Train/validation/calibration/test split\n    train_records, temp_records = train_test_split(\n        records, test_size=val_fraction + calib_fraction + 0.15, \n        stratify=labels_all, random_state=seed\n    )\n    \n    temp_labels = np.array([r.label for r in temp_records])\n    remaining_size = val_fraction + calib_fraction + 0.15\n    calib_size = calib_fraction / remaining_size\n    \n    calib_records, temp2_records = train_test_split(\n        temp_records, test_size=(1 - calib_size), \n        stratify=temp_labels, random_state=seed\n    )\n    \n    temp2_labels = np.array([r.label for r in temp2_records])\n    val_size = val_fraction / (val_fraction + 0.15)\n    \n    val_records, test_records = train_test_split(\n        temp2_records, test_size=(1 - val_size),\n        stratify=temp2_labels, random_state=seed\n    )\n    \n    print(f\"\\nðŸ”„ Data Split:\")\n    print(f\"   Training: {len(train_records)} images\")\n    print(f\"   Validation: {len(val_records)} images\") \n    print(f\"   Calibration: {len(calib_records)} images\")\n    print(f\"   Test: {len(test_records)} images\")\n    \n    # Create datasets\n    train_ds = AlzheimerDataset(train_records, image_size=image_size, augment=True)\n    val_ds = AlzheimerDataset(val_records, image_size=image_size, augment=False)\n    calib_ds = AlzheimerDataset(calib_records, image_size=image_size, augment=False)\n    test_ds = AlzheimerDataset(test_records, image_size=image_size, augment=False)\n    \n    # Create data loaders\n    train_loader = DataLoader(\n        train_ds, batch_size=batch_size, shuffle=True, \n        num_workers=num_workers, pin_memory=True, worker_init_fn=worker_init_fn,\n        drop_last=True  # Drop incomplete last batch to avoid BatchNorm issues\n    )\n    val_loader = DataLoader(\n        val_ds, batch_size=batch_size, shuffle=False, \n        num_workers=num_workers, pin_memory=True\n    )\n    calib_loader = DataLoader(\n        calib_ds, batch_size=batch_size, shuffle=False, \n        num_workers=num_workers, pin_memory=True\n    )\n    test_loader = DataLoader(\n        test_ds, batch_size=batch_size, shuffle=False, \n        num_workers=num_workers, pin_memory=True\n    )\n    \n    num_classes = len(ALZHEIMER_LABEL_MAP)\n    class_names = [ALZHEIMER_CLINICAL_INFO[i]['name'] for i in range(num_classes)]\n    \n    # Build and train model based on ensemble method\n    print(f\"\\nðŸ—ï¸  Building {ensemble_method} model...\")\n    \n    if ensemble_method == 'batch_ensemble':\n        # Create backbone without classifier\n        backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n        model = OptimizedBatchEnsemble(backbone, num_classes, ensemble_size).to(device())\n        \n        # Training\n        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n        \n        print(f\"\\nðŸš€ Training Batch Ensemble ({ensemble_size} members)...\")\n        best_val_acc = -1.0\n        best_state = None\n        \n        for epoch in range(1, epochs + 1):\n            # Training\n            if use_mixup:\n                tr_loss, tr_acc = train_epoch_with_mixup(model, train_loader, optimizer, device())\n            else:\n                model.train()\n                tr_loss = tr_acc = 0.0  # Simplified for batch ensemble\n            \n            # Validation\n            val_results = comprehensive_evaluation(model, val_loader, device(), class_names)\n            val_acc = val_results['accuracy']\n            \n            scheduler.step()\n            \n            if epoch % max(1, epochs // 5) == 0:\n                print(f\"   Epoch {epoch:02d}/{epochs} | Val Acc: {val_acc:.4f} | Val F1: {val_results['f1_macro']:.4f}\")\n            \n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n        \n        if best_state:\n            model.load_state_dict(best_state)\n    \n    else:  # mc_dropout or other methods\n        if model_name == 'resnet18':  # Use simple model for resnet18\n            model = build_simple_model(model_name, num_classes, dropout, pretrained=True).to(device())\n        else:\n            model = build_medical_model(model_name, num_classes, dropout, pretrained=True).to(device())\n        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n        \n        print(f\"\\nðŸš€ Training Medical Model...\")\n        best_val_acc = -1.0\n        best_state = None\n        \n        for epoch in range(1, epochs + 1):\n            # Training\n            if use_mixup:\n                tr_loss, tr_acc = train_epoch_with_mixup(model, train_loader, optimizer, device())\n            else:\n                model.train()\n                total_loss = total_correct = total = 0\n                for images, targets in train_loader:\n                    images, targets = images.to(device()), targets.to(device())\n                    optimizer.zero_grad()\n                    logits = model(images)\n                    loss = F.cross_entropy(logits, targets)\n                    loss.backward()\n                    optimizer.step()\n                    \n                    total_loss += loss.item() * images.size(0)\n                    preds = torch.argmax(logits, dim=1)\n                    total_correct += (preds == targets).sum().item()\n                    total += images.size(0)\n                \n                tr_loss = total_loss / total\n                tr_acc = total_correct / total\n            \n            # Validation\n            val_results = comprehensive_evaluation(model, val_loader, device(), class_names)\n            val_acc = val_results['accuracy']\n            \n            scheduler.step()\n            \n            if epoch % max(1, epochs // 5) == 0:\n                print(f\"   Epoch {epoch:02d}/{epochs} | Train: {tr_acc:.3f} | Val: {val_acc:.3f} | F1: {val_results['f1_macro']:.3f}\")\n            \n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n        \n        if best_state:\n            model.load_state_dict(best_state)\n    \n    # Comprehensive evaluation\n    print(f\"\\nðŸ“Š Final Model Evaluation...\")\n    test_results = comprehensive_evaluation(model, test_loader, device(), class_names)\n    print(f\"   Test Accuracy: {test_results['accuracy']:.4f}\")\n    print(f\"   Test F1 (Macro): {test_results['f1_macro']:.4f}\")\n    print(f\"   Test F1 (Weighted): {test_results['f1_weighted']:.4f}\")\n    \n    # Advanced uncertainty quantification\n    print(f\"\\nðŸŽ² Uncertainty Quantification ({ensemble_method})...\")\n    \n    if ensemble_method == 'mc_dropout':\n        mean_preds, mc_preds, uncertainty_metrics = monte_carlo_predictions(\n            model, test_loader, device(), mc_samples\n        )\n    elif ensemble_method == 'batch_ensemble':\n        mean_preds, mc_preds, uncertainty_metrics = batch_ensemble_predictions(\n            model, test_loader, device()\n        )\n    else:\n        # Fallback to MC dropout\n        mean_preds, mc_preds, uncertainty_metrics = monte_carlo_predictions(\n            model, test_loader, device(), mc_samples\n        )\n    \n    print(f\"   Mean Predictive Entropy: {np.mean(uncertainty_metrics['predictive_entropy']):.4f}\")\n    print(f\"   Mean Epistemic Uncertainty: {np.mean(uncertainty_metrics['epistemic_uncertainty']):.4f}\")\n    print(f\"   Mean Aleatoric Uncertainty: {np.mean(uncertainty_metrics['aleatoric_uncertainty']):.4f}\")\n    \n    # Advanced temperature scaling and calibration\n    print(f\"\\nðŸŒ¡ï¸  Advanced Temperature Scaling...\")\n    temp_scaler = fit_advanced_temperature(model, calib_loader, device(), num_classes)\n    \n    # Apply temperature scaling to test predictions\n    test_logits = test_results['logits']\n    with torch.no_grad():\n        test_logits_tensor = torch.from_numpy(test_logits).to(device())\n        scaled_logits = temp_scaler(test_logits_tensor).cpu().numpy()\n    \n    scaled_probs = softmax_np(scaled_logits)\n    \n    # RAPS Conformal Prediction with enhancements\n    print(f\"\\nðŸŽ¯ Enhanced RAPS Conformal Prediction...\")\n    \n    # Get calibration predictions with temperature scaling\n    calib_results = comprehensive_evaluation(model, calib_loader, device(), class_names)\n    calib_logits = calib_results['logits']\n    calib_labels = np.array(calib_results['labels'])\n    \n    with torch.no_grad():\n        calib_logits_tensor = torch.from_numpy(calib_logits).to(device())\n        calib_scaled_logits = temp_scaler(calib_logits_tensor).cpu().numpy()\n    \n    calib_scaled_probs = softmax_np(calib_scaled_logits)\n    \n    # Compute class weights for balanced RAPS\n    class_counts_array = np.array([label_counts.get(i, 1) for i in range(num_classes)])\n    class_weights = 1.0 / (class_counts_array / class_counts_array.sum())\n    class_weights = class_weights / class_weights.sum() * num_classes\n    \n    # Enhanced RAPS scores\n    calib_scores = compute_raps_scores_enhanced(\n        calib_scaled_probs, calib_labels, lambda_reg, k_reg, class_weights\n    )\n    \n    # Adaptive quantile with confidence intervals\n    qhat, (qhat_ci_low, qhat_ci_high) = adaptive_raps_quantile(calib_scores, alpha)\n    \n    # Build prediction sets\n    def build_prediction_sets(probs: np.ndarray, q: float) -> List[List[int]]:\n        n, num_classes = probs.shape\n        sets = []\n        for i in range(n):\n            p = probs[i] * class_weights\n            p = p / p.sum()\n            \n            order = np.argsort(p)[::-1]\n            cum_prob = 0.0\n            pred_set = []\n            \n            for rank, cls_idx in enumerate(order):\n                reg = lambda_reg * max(rank - k_reg, 0)\n                if cum_prob + p[cls_idx] + reg <= q + 1e-12:\n                    cum_prob += p[cls_idx]\n                    pred_set.append(cls_idx)\n                else:\n                    break\n            \n            if not pred_set:\n                pred_set = [int(order[0])]\n            \n            sets.append(pred_set)\n        \n        return sets\n    \n    test_labels = np.array(test_results['labels'])\n    pred_sets = build_prediction_sets(scaled_probs, qhat)\n    \n    # Calculate coverage and efficiency\n    coverage = np.mean([test_labels[i] in pred_sets[i] for i in range(len(test_labels))])\n    avg_set_size = np.mean([len(s) for s in pred_sets])\n    \n    print(f\"   RAPS Coverage (Î±={alpha}): {coverage:.3f} (target: {1-alpha:.3f})\")\n    print(f\"   Average Set Size: {avg_set_size:.3f}\")\n    print(f\"   Quantile: {qhat:.4f} (CI: {qhat_ci_low:.4f} - {qhat_ci_high:.4f})\")\n    \n    # Generate advanced visualizations\n    print(f\"\\nðŸŽ¨ Generating Advanced Visualizations...\")\n    \n    try:\n        # Select interesting test cases for visualization\n        vis_indices = []\n        for label in range(num_classes):\n            label_indices = [i for i, l in enumerate(test_labels) if l == label]\n            if label_indices:\n                # Pick case with high uncertainty\n                uncertainties = uncertainty_metrics['epistemic_uncertainty'][label_indices]\n                high_unc_idx = label_indices[np.argmax(uncertainties)]\n                vis_indices.append(high_unc_idx)\n        \n        vis_indices = vis_indices[:6]  # Limit to 6 visualizations\n        \n        for idx in vis_indices:\n            try:\n                x, y = test_ds[idx]\n                true_label = int(y)\n                pred_set = pred_sets[idx]\n                uncertainty = uncertainty_metrics['epistemic_uncertainty'][idx]\n                \n                # Generate uncertainty-aware Grad-CAM\n                images_tensor = x.unsqueeze(0).to(device())\n                \n                for class_idx in pred_set:\n                    try:\n                        mean_cam, std_cam = generate_uncertainty_aware_gradcam(\n                            model, images_tensor, class_idx, num_mc_samples=10\n                        )\n                        \n                        # Save visualizations\n                        clinical_info = ALZHEIMER_CLINICAL_INFO[class_idx]\n                        true_clinical = ALZHEIMER_CLINICAL_INFO[true_label]\n                        \n                        # Convert tensor to image\n                        img_np = x.numpy().transpose(1, 2, 0)\n                        mean = np.array([0.485, 0.456, 0.406])\n                        std = np.array([0.229, 0.224, 0.225])\n                        img_vis = np.clip(img_np * std + mean, 0, 1)\n                        \n                        # Create overlays\n                        mean_overlay = show_cam_on_image(img_vis, mean_cam, use_rgb=True)\n                        \n                        # Uncertainty heatmap\n                        uncertainty_norm = (std_cam - std_cam.min()) / (std_cam.ptp() + 1e-8)\n                        uncertainty_color = np.zeros_like(img_vis)\n                        uncertainty_color[:, :, 0] = uncertainty_norm  # Red channel for uncertainty\n                        uncertainty_overlay = (0.7 * img_vis + 0.3 * uncertainty_color) * 255\n                        uncertainty_overlay = uncertainty_overlay.astype(np.uint8)\n                        \n                        # Save images\n                        base_name = f\"case_{idx}_true_{true_clinical['name'].replace(' ', '')}_pred_{clinical_info['name'].replace(' ', '')}\"\n                        Image.fromarray(mean_overlay).save(\n                            os.path.join(output_dir, f\"{base_name}_gradcam.png\")\n                        )\n                        Image.fromarray(uncertainty_overlay).save(\n                            os.path.join(output_dir, f\"{base_name}_uncertainty.png\")\n                        )\n                        \n                    except Exception as e:\n                        print(f\"Warning: Visualization failed for case {idx}, class {class_idx}: {e}\")\n                        continue\n                        \n            except Exception as e:\n                print(f\"Warning: Failed to process visualization case {idx}: {e}\")\n                continue\n    \n    except Exception as e:\n        print(f\"Warning: Visualization generation failed: {e}\")\n    \n    # Save comprehensive results\n    print(f\"\\nðŸ’¾ Saving Results...\")\n    \n    results = {\n        # Model and training info\n        'model_name': model_name,\n        'ensemble_method': ensemble_method,\n        'ensemble_size': ensemble_size,\n        'epochs': epochs,\n        'learning_rate': lr,\n        'dropout': dropout,\n        'use_mixup': use_mixup,\n        \n        # Dataset info\n        'dataset_size': len(records),\n        'train_size': len(train_records),\n        'val_size': len(val_records),\n        'calib_size': len(calib_records),\n        'test_size': len(test_records),\n        'class_distribution': label_counts,\n        \n        # Performance metrics\n        'test_accuracy': float(test_results['accuracy']),\n        'test_f1_macro': float(test_results['f1_macro']),\n        'test_f1_weighted': float(test_results['f1_weighted']),\n        'test_loss': float(test_results['loss']),\n        \n        # Uncertainty metrics\n        'uncertainty_metrics': {\n            k: {\n                'mean': float(np.mean(v)),\n                'std': float(np.std(v)),\n                'min': float(np.min(v)),\n                'max': float(np.max(v))\n            } for k, v in uncertainty_metrics.items()\n        },\n        \n        # Conformal prediction\n        'conformal_prediction': {\n            'alpha': alpha,\n            'lambda_reg': lambda_reg,\n            'k_reg': k_reg,\n            'coverage': float(coverage),\n            'average_set_size': float(avg_set_size),\n            'quantile': float(qhat),\n            'quantile_ci_lower': float(qhat_ci_low),\n            'quantile_ci_upper': float(qhat_ci_high)\n        },\n        \n        # Clinical interpretation\n        'clinical_info': ALZHEIMER_CLINICAL_INFO\n    }\n    \n    if 'classification_report' in test_results:\n        results['classification_report'] = test_results['classification_report']\n    \n    # Save to JSON\n    with open(os.path.join(output_dir, 'comprehensive_results.json'), 'w') as f:\n        json.dump(results, f, indent=2)\n    \n    # Save prediction details\n    prediction_details = {\n        'test_predictions': [int(p) for p in test_results['predictions']],\n        'test_labels': [int(l) for l in test_labels],\n        'prediction_sets': [[int(c) for c in ps] for ps in pred_sets],\n        'uncertainty_scores': {k: v.tolist() for k, v in uncertainty_metrics.items()},\n        'scaled_probabilities': scaled_probs.tolist()\n    }\n    \n    with open(os.path.join(output_dir, 'prediction_details.json'), 'w') as f:\n        json.dump(prediction_details, f, indent=2)\n    \n    print(f\"\\nâœ… Pipeline Complete!\")\n    print(f\"ðŸ“ Results saved to: {output_dir}\")\n    print(f\"ðŸ† Test Accuracy: {test_results['accuracy']:.4f}\")\n    print(f\"ðŸŽ¯ Conformal Coverage: {coverage:.3f} (target: {1-alpha:.3f})\")\n    print(f\"ðŸ“Š Average Prediction Set Size: {avg_set_size:.3f}\")\n    print(\"=\" * 80)\n\n\n# ------------------------------\n# CLI\n# ------------------------------\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description=\"Advanced Alzheimer MRI Analysis with Uncertainty Quantification & Explainability\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    \n    # Dataset and I/O\n    parser.add_argument('--data_root', type=str, \n                       default=os.environ.get('DATA_ROOT', '/kaggle/input/augmented-alzheimer-mri-dataset'),\n                       help='Root directory containing Alzheimer MRI dataset')\n    parser.add_argument('--output_dir', type=str, \n                       default=os.environ.get('OUTPUT_DIR', './alzheimer_analysis_outputs'),\n                       help='Output directory for results and visualizations')\n    \n    # Model configuration\n    parser.add_argument('--model_name', type=str, \n                       default=os.environ.get('MODEL_NAME', 'tf_efficientnet_b0_ns'),\n                       help='Backbone model architecture')\n    parser.add_argument('--ensemble_method', type=str, \n                       default=os.environ.get('ENSEMBLE_METHOD', 'batch_ensemble'),\n                       choices=['mc_dropout', 'batch_ensemble'],\n                       help='Ensemble method for uncertainty quantification')\n    parser.add_argument('--ensemble_size', type=int, \n                       default=int(os.environ.get('ENSEMBLE_SIZE', 4)),\n                       help='Number of ensemble members')\n    \n    # Training parameters\n    parser.add_argument('--image_size', type=int, default=int(os.environ.get('IMAGE_SIZE', 224)))\n    parser.add_argument('--batch_size', type=int, default=int(os.environ.get('BATCH_SIZE', 16)))\n    parser.add_argument('--epochs', type=int, default=int(os.environ.get('EPOCHS', 15)))\n    parser.add_argument('--lr', type=float, default=float(os.environ.get('LR', 2e-4)))\n    parser.add_argument('--weight_decay', type=float, default=float(os.environ.get('WEIGHT_DECAY', 1e-4)))\n    parser.add_argument('--dropout', type=float, default=float(os.environ.get('DROPOUT', 0.25)))\n    parser.add_argument('--use_mixup', action='store_true', default=True,\n                       help='Use mixup augmentation for training')\n    \n    # Uncertainty and conformal prediction\n    parser.add_argument('--alpha', type=float, default=float(os.environ.get('ALPHA', 0.1)),\n                       help='Miscoverage rate for conformal prediction sets')\n    parser.add_argument('--lambda_reg', type=float, default=float(os.environ.get('LAMBDA_REG', 0.05)),\n                       help='RAPS regularization parameter')\n    parser.add_argument('--k_reg', type=int, default=int(os.environ.get('K_REG', 1)),\n                       help='RAPS rank threshold for regularization')\n    parser.add_argument('--mc_samples', type=int, default=int(os.environ.get('MC_SAMPLES', 20)),\n                       help='Number of Monte Carlo samples for uncertainty estimation')\n    \n    # Data splitting\n    parser.add_argument('--val_fraction', type=float, default=float(os.environ.get('VAL_FRACTION', 0.2)))\n    parser.add_argument('--calib_fraction', type=float, default=float(os.environ.get('CALIB_FRACTION', 0.2)))\n    \n    # System\n    parser.add_argument('--num_workers', type=int, default=int(os.environ.get('NUM_WORKERS', 2)))\n    parser.add_argument('--seed', type=int, default=int(os.environ.get('SEED', 42)))\n    \n    return parser.parse_args()\n\n\ndef run_simple_and_safe(\n    data_root: str = '/kaggle/input/augmented-alzheimer-mri-dataset',\n    output_dir: str = '/kaggle/working/alzheimer_results'\n) -> None:\n    \"\"\"\n    Super simple, guaranteed-to-work version for Kaggle\n    \"\"\"\n    print(\"ðŸ›¡ï¸  Running SIMPLE & SAFE version (guaranteed to work)\")\n    print(\"ðŸ“š Still includes: RAPS, MC Dropout, Temperature Scaling, Grad-CAM\")\n    \n    run_alzheimer_pipeline(\n        data_root=data_root,\n        output_dir=output_dir,\n        model_name='resnet18',  # Simpler model\n        image_size=224,\n        batch_size=64,          # Larger batch to avoid small batch issues\n        epochs=5,               # Fewer epochs\n        lr=1e-3,               # Standard learning rate\n        weight_decay=1e-4,\n        alpha=0.1,\n        lambda_reg=0.0,         # Simplified RAPS\n        k_reg=0,\n        dropout=0.2,            # Lower dropout\n        num_workers=0,          # No multiprocessing\n        calib_fraction=0.15,    # Smaller calibration set\n        val_fraction=0.15,\n        mc_samples=10,          # Fewer MC samples\n        seed=42,\n        ensemble_method='mc_dropout',\n        ensemble_size=1,\n        use_mixup=False,        # No mixup for simplicity\n    )\n\n\ndef quick_test_run(\n    data_root: str = '/kaggle/input/augmented-alzheimer-mri-dataset',\n    output_dir: str = '/kaggle/working/alzheimer_results'\n) -> None:\n    \"\"\"\n    Quick test run with minimal settings to ensure everything works\n    \"\"\"\n    print(\"ðŸ§ª Running Quick Test (2 epochs, MC Dropout)\")\n    print(\"This will complete in ~5 minutes to verify everything works\")\n    \n    run_alzheimer_pipeline(\n        data_root=data_root,\n        output_dir=output_dir,\n        model_name='tf_efficientnet_b0_ns',\n        image_size=224,\n        batch_size=32,  # Larger batch for speed\n        epochs=2,       # Just 2 epochs for testing\n        lr=3e-4,\n        weight_decay=1e-4,\n        alpha=0.1,\n        lambda_reg=0.05,\n        k_reg=1,\n        dropout=0.25,\n        num_workers=2,\n        calib_fraction=0.2,\n        val_fraction=0.2,\n        mc_samples=10,  # Fewer samples for speed\n        seed=42,\n        ensemble_method='mc_dropout',\n        ensemble_size=4,\n        use_mixup=False,  # Disable mixup for speed\n    )\n\n\ndef run_with_fallback(\n    data_root: str = '/kaggle/input/augmented-alzheimer-mri-dataset',\n    output_dir: str = '/kaggle/working/alzheimer_results',\n    model_name: str = 'tf_efficientnet_b0_ns',\n    epochs: int = 10,\n    batch_size: int = 16,\n    lr: float = 2e-4,\n    alpha: float = 0.1,\n    mc_samples: int = 15\n) -> None:\n    \"\"\"\n    Fallback function that tries batch_ensemble first, then mc_dropout if it fails.\n    Ensures the pipeline runs successfully in Kaggle.\n    \"\"\"\n    print(\"ðŸ”¥ Running Alzheimer MRI Analysis with Smart Fallback\")\n    print(f\"ðŸ“ Data: {data_root}\")\n    print(f\"ðŸ’¾ Output: {output_dir}\")\n    \n    # Try batch_ensemble first\n    try:\n        print(\"ðŸ¤– Attempting Batch Ensemble...\")\n        run_alzheimer_pipeline(\n            data_root=data_root,\n            output_dir=output_dir,\n            model_name=model_name,\n            image_size=224,\n            batch_size=batch_size,\n            epochs=epochs,\n            lr=lr,\n            weight_decay=1e-4,\n            alpha=alpha,\n            lambda_reg=0.05,\n            k_reg=1,\n            dropout=0.25,\n            num_workers=2,\n            calib_fraction=0.2,\n            val_fraction=0.2,\n            mc_samples=mc_samples,\n            seed=42,\n            ensemble_method='batch_ensemble',\n            ensemble_size=4,\n            use_mixup=True,\n        )\n        print(\"âœ… Batch Ensemble completed successfully!\")\n        \n    except Exception as e:\n        print(f\"âš ï¸  Batch Ensemble failed: {e}\")\n        print(\"ðŸ”„ Switching to MC Dropout fallback...\")\n        \n        try:\n            run_alzheimer_pipeline(\n                data_root=data_root,\n                output_dir=output_dir,\n                model_name=model_name,\n                image_size=224,\n                batch_size=batch_size,\n                epochs=epochs,\n                lr=lr,\n                weight_decay=1e-4,\n                alpha=alpha,\n                lambda_reg=0.05,\n                k_reg=1,\n                dropout=0.25,\n                num_workers=2,\n                calib_fraction=0.2,\n                val_fraction=0.2,\n                mc_samples=mc_samples,\n                seed=42,\n                ensemble_method='mc_dropout',\n                ensemble_size=4,\n                use_mixup=True,\n            )\n            print(\"âœ… MC Dropout completed successfully!\")\n            \n        except Exception as e2:\n            print(f\"âŒ Both methods failed. Error: {e2}\")\n            raise e2\n\n\ndef run_with_defaults(\n    data_root: str = '/kaggle/input/augmented-alzheimer-mri-dataset',\n    output_dir: str = '/kaggle/working/alzheimer_results',\n    model_name: str = 'tf_efficientnet_b0_ns',\n    ensemble_method: str = 'mc_dropout',  # Changed to mc_dropout for reliability\n    ensemble_size: int = 4,\n    epochs: int = 10,  # Reduced for faster completion\n    batch_size: int = 16,\n    lr: float = 2e-4,\n    alpha: float = 0.1,\n    mc_samples: int = 15\n) -> None:\n    \"\"\"\n    Run the pipeline with sensible defaults for Kaggle/Colab environments.\n    This avoids argparse issues in Jupyter notebooks.\n    \"\"\"\n    print(\"ðŸ” Detected notebook environment - using default parameters\")\n    print(\"ðŸ”¥ Running Alzheimer MRI Uncertainty Analysis with Default Parameters\")\n    print(f\"ðŸ“ Data: {data_root}\")\n    print(f\"ðŸ’¾ Output: {output_dir}\")\n    print(f\"ðŸ¤– Method: {ensemble_method}\")\n    print(f\"â±ï¸  Epochs: {epochs}\")\n    \n    run_alzheimer_pipeline(\n        data_root=data_root,\n        output_dir=output_dir,\n        model_name=model_name,\n        image_size=224,\n        batch_size=batch_size,\n        epochs=epochs,\n        lr=lr,\n        weight_decay=1e-4,\n        alpha=alpha,\n        lambda_reg=0.05,\n        k_reg=1,\n        dropout=0.25,\n        num_workers=2,\n        calib_fraction=0.2,\n        val_fraction=0.2,\n        mc_samples=mc_samples,\n        seed=42,\n        ensemble_method=ensemble_method,\n        ensemble_size=ensemble_size,\n        use_mixup=True,\n    )\n\n\ndef is_notebook_environment() -> bool:\n    \"\"\"Detect if running in Jupyter/Colab/Kaggle notebook\"\"\"\n    try:\n        from IPython import get_ipython\n        return get_ipython() is not None\n    except ImportError:\n        return False\n\n\ndef main() -> None:\n    # Check if running in notebook environment\n    if is_notebook_environment():\n        print(\"ðŸ” Detected notebook environment - using SIMPLE & SAFE version\")\n        print(\"ðŸ“š This includes all key methods: RAPS, MC Dropout, Temperature Scaling, Grad-CAM\")\n        run_simple_and_safe()\n        return\n    \n    # Standard command-line execution\n    args = parse_args()\n    \n    # Validate data root\n    if not exists(args.data_root):\n        print(f\"âŒ Data root not found: {args.data_root}\")\n        print(f\"\")\n        print(f\"For Kaggle:\")\n        print(f\"  1. Add dataset: 'uraninjo/augmented-alzheimer-mri-dataset'\")\n        print(f\"  2. Set data_root: '/kaggle/input/augmented-alzheimer-mri-dataset'\")\n        print(f\"\")\n        print(f\"Expected folder structure:\")\n        print(f\"  {args.data_root}/\")\n        print(f\"  â”œâ”€â”€ NonDemented/\")\n        print(f\"  â”œâ”€â”€ VeryMildDemented/\")\n        print(f\"  â”œâ”€â”€ MildDemented/\")\n        print(f\"  â””â”€â”€ ModerateDemented/\")\n        sys.exit(1)\n    \n    # Check dependencies\n    missing = []\n    if timm is None:\n        missing.append('timm')\n    if GradCAM is None:\n        missing.append('pytorch-grad-cam')\n    if train_test_split is None:\n        missing.append('scikit-learn')\n    \n    if missing:\n        print(f\"âŒ Missing packages: {missing}\")\n        print(f\"Install with: pip install {' '.join(missing)}\")\n        sys.exit(1)\n    \n    # Run the pipeline\n    run_alzheimer_pipeline(\n        data_root=args.data_root,\n        output_dir=args.output_dir,\n        model_name=args.model_name,\n        image_size=args.image_size,\n        batch_size=args.batch_size,\n        epochs=args.epochs,\n        lr=args.lr,\n        weight_decay=args.weight_decay,\n        alpha=args.alpha,\n        lambda_reg=args.lambda_reg,\n        k_reg=args.k_reg,\n        dropout=args.dropout,\n        num_workers=args.num_workers,\n        calib_fraction=args.calib_fraction,\n        val_fraction=args.val_fraction,\n        mc_samples=args.mc_samples,\n        seed=args.seed,\n        ensemble_method=args.ensemble_method,\n        ensemble_size=args.ensemble_size,\n        use_mixup=args.use_mixup,\n    )\n\n\nif __name__ == '__main__':\n    main()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-15T11:09:25.160938Z","iopub.execute_input":"2025-08-15T11:09:25.161284Z","iopub.status.idle":"2025-08-15T11:31:09.732492Z","shell.execute_reply.started":"2025-08-15T11:09:25.161258Z","shell.execute_reply":"2025-08-15T11:31:09.731771Z"}},"outputs":[],"execution_count":null}]}